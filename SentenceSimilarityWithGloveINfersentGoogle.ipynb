{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Simple Sentence Similarity (from github) - with application of the methods to a sample dataset at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries ```seaborn```, ```tensorflow``` and ```tensorflow_hub``` are not included in the basic setup of the environment (requirements.txt) because of their size. At first you may need to install them. If you encounter \"module not found\" error, uncomment the lines below and run the cell in order to install them in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 intall seaborn\n",
    "# !pip3 install tensorflow\n",
    "# !pip3 install tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STS Benchmark\n",
    "\n",
    "The STS Benchmark brings together the English data from the SemEval sentence similarity tasks between 2012 and 2017. The data is split in training, development and test data: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_sts_dataset(filename):\n",
    "    # Loads a subset of the STS dataset into a DataFrame. In particular both\n",
    "    # sentences and their human rated similarity score.\n",
    "    sent_pairs = []\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            ts = line.strip().split(\"\\t\")\n",
    "            sent_pairs.append((ts[5], ts[6], float(ts[4])))\n",
    "    return pd.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n",
    "\n",
    "\n",
    "def download_and_load_sts_data():\n",
    "    sts_dataset = tf.keras.utils.get_file(\n",
    "        fname=\"Stsbenchmark.tar.gz\",\n",
    "        origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
    "        extract=True)\n",
    "\n",
    "    sts_dev = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n",
    "    sts_test = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n",
    "\n",
    "    return sts_dev, sts_test\n",
    "\n",
    "sts_dev, sts_test = download_and_load_sts_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A girl is styling her hair.</td>\n",
       "      <td>A girl is brushing her hair.</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sent_1  \\\n",
       "0                    A girl is styling her hair.   \n",
       "1       A group of men play soccer on the beach.   \n",
       "2  One woman is measuring another woman's ankle.   \n",
       "3                A man is cutting up a cucumber.   \n",
       "4                       A man is playing a harp.   \n",
       "\n",
       "                                             sent_2  sim  \n",
       "0                      A girl is brushing her hair.  2.5  \n",
       "1  A group of boys are playing soccer on the beach.  3.6  \n",
       "2           A woman measures another woman's ankle.  5.0  \n",
       "3                      A man is slicing a cucumber.  4.2  \n",
       "4                      A man is playing a keyboard.  1.5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "class Sentence:\n",
    "    \n",
    "    def __init__(self, sentence):\n",
    "        self.raw = sentence\n",
    "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n",
    "        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SICK data\n",
    "\n",
    "The SICK dataset contains 10,000 English sentence pairs labelled with their semantic relatedness and entailment relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_sick(f): \n",
    "\n",
    "    response = requests.get(f).text\n",
    "\n",
    "    lines = response.split(\"\\n\")[1:]\n",
    "    lines = [l.split(\"\\t\") for l in lines if len(l) > 0]\n",
    "    lines = [l for l in lines if len(l) == 5]\n",
    "\n",
    "    df = pd.DataFrame(lines, columns=[\"idx\", \"sent_1\", \"sent_2\", \"sim\", \"label\"])\n",
    "    df['sim'] = pd.to_numeric(df['sim'])\n",
    "    return df\n",
    "    \n",
    "sick_train = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_train.txt\")\n",
    "sick_dev = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_trial.txt\")\n",
    "sick_test = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_test_annotated.txt\")\n",
    "sick_all = sick_train.append(sick_test).append(sick_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "      <th>sim</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx                                             sent_1  \\\n",
       "0   1  A group of kids is playing in a yard and an ol...   \n",
       "1   2  A group of children is playing in the house an...   \n",
       "2   3  The young boys are playing outdoors and the ma...   \n",
       "3   5  The kids are playing outdoors near a man with ...   \n",
       "4   9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                              sent_2  sim       label  \n",
       "0  A group of boys in a yard is playing and a man...  4.5     NEUTRAL  \n",
       "1  A group of kids is playing in a yard and an ol...  3.2     NEUTRAL  \n",
       "2  The kids are playing outdoors near a man with ...  4.7  ENTAILMENT  \n",
       "3  A group of kids is playing in a yard and an ol...  3.4     NEUTRAL  \n",
       "4  A group of kids is playing in a yard and an ol...  3.7     NEUTRAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sick_all[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InferSent\n",
    "\n",
    "[InferSent](https://github.com/facebookresearch/InferSent) is a pre-trained encoder that produces sentence embeddings. \n",
    "More particularly, it is a BiLSTM with max pooling that was trained on the SNLI dataset, 570k English sentence pairs labelled with one of three categories: entailment, contradiction or neutral. InferSent was developed and trained by Facebook Research.\n",
    "\n",
    "Let's first download the resources we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# !wget -nc https://raw.githubusercontent.com/facebookresearch/InferSent/master/models.py\n",
    "# !wget -nc https://s3.amazonaws.com/senteval/infersent/infersent.allnli.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first time you need to download the infersent1.pkl model. Uncomment and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: encoder: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  146M  100  146M    0     0  4366k      0  0:00:34  0:00:34 --:--:-- 6723k 0  3924k      0  0:00:38  0:00:28  0:00:10 5681k\n"
     ]
    }
   ],
   "source": [
    "# !mkdir encoder\n",
    "# !curl -Lo encoder/infersent1.pkl https://s3.amazonaws.com/senteval/infersent/infersent1.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infersent uses glove model. You can download it by uncommenting and running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -Lo models/ https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "# !cd models && unzip glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_GLOVE = os.path.expanduser(\"models/glove.840B.300d.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from models import InferSent\n",
    "V = 1\n",
    "MODEL_PATH = 'models/infersent1.pkl'\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))\n",
    "infersent.set_w2v_path(PATH_TO_GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # infersent = torch.load('infersent.allnli.pickle')\n",
    "\n",
    "# infersent = torch.load('infersent.allnli.pickle', map_location=lambda storage, loc: storage)\n",
    "# infersent.use_cuda = False\n",
    "# infersent.set_glove_path(PATH_TO_GLOVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the benchmark by having InferSent encode the two sets of sentences and compute the cosine similarity between the corresponding sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def run_inf_benchmark(sentences1, sentences2):\n",
    "    \n",
    "    raw_sentences1 = [sent1.raw for sent1 in sentences1]\n",
    "    raw_sentences2 = [sent2.raw for sent2 in sentences2]\n",
    "    \n",
    "    infersent.build_vocab(raw_sentences1 + raw_sentences2, tokenize=True)\n",
    "    embeddings1 = infersent.encode(raw_sentences1, tokenize=True)\n",
    "    embeddings2 = infersent.encode(raw_sentences2, tokenize=True)\n",
    "    \n",
    "    inf_sims = []\n",
    "    for (emb1, emb2) in zip(embeddings1, embeddings2): \n",
    "        sim = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "        inf_sims.append(sim)\n",
    "\n",
    "    return inf_sims   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Sentence Encoder\n",
    "\n",
    "The [Google Sentence Encoder](https://www.tensorflow.org/hub/modules/google/universal-sentence-encoder/1) is Google's answer to Facebook's InferSent. It comes in two forms: \n",
    "\n",
    "- a Transformer model that takes the element-wise sum of the context-aware word representations produced by the encoding subgraph of a Transformer model.\n",
    "- a Deep Averaging Network (DAN) where input embeddings for words and bigrams are averaged together and passed through a feed-forward deep neural network.\n",
    "\n",
    "The Transformer model tends to give better results, but at the time of writing, only the DAN-based encoder was available.\n",
    "\n",
    "In contrast to InferSent, the Google Sentence Encoder was trained on a combination of unsupervised data (in a skip-thought-like task) and supervised data (the SNLI corpus).\n",
    "\n",
    "The Google Sentence Encoder can be loaded from the Tensorflow Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "#in case ssl errors appear\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like InferSent above, we'll have the it encode the two sets of sentences and return the similarities between the embeddings it produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gse_benchmark(sentences1, sentences2):\n",
    "    sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "    sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "    sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\n",
    "    sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\n",
    "        \n",
    "    sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "      \n",
    "        [gse_sims] = session.run(\n",
    "            [sim_scores],\n",
    "            feed_dict={\n",
    "                sts_input1: [sent1.raw for sent1 in sentences1],\n",
    "                sts_input2: [sent2.raw for sent2 in sentences2]\n",
    "            })\n",
    "    return gse_sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Finally, it's time to run the actual experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(df, benchmarks): \n",
    "    \n",
    "    sentences1 = [Sentence(s) for s in df['sent_1']]\n",
    "    sentences2 = [Sentence(s) for s in df['sent_2']]\n",
    "    \n",
    "    pearson_cors, spearman_cors = [], []\n",
    "    for label, method in benchmarks:\n",
    "        sims = method(sentences1, sentences2)\n",
    "        pearson_correlation = scipy.stats.pearsonr(sims, df['sim'])[0]\n",
    "        print(label, pearson_correlation)\n",
    "        pearson_cors.append(pearson_correlation)\n",
    "        spearman_correlation = scipy.stats.spearmanr(sims, df['sim'])[0]\n",
    "        spearman_cors.append(spearman_correlation)\n",
    "        \n",
    "    return pearson_cors, spearman_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE 0.7282557455668891\n"
     ]
    }
   ],
   "source": [
    "import functools as ft\n",
    "\n",
    "benchmarks = [\n",
    "              (\"GSE\", run_gse_benchmark),\n",
    "              (\"INF\", run_inf_benchmark)\n",
    "             ]\n",
    "\n",
    "global PYEMD_EXT\n",
    "pearson_results, spearman_results = {}, {}\n",
    "pearson_results[\"SICK-DEV\"], spearman_results[\"SICK-DEV\"] = run_experiment(sick_dev, benchmarks)\n",
    "pearson_results[\"SICK-TEST\"], spearman_results[\"SICK-TEST\"] = run_experiment(sick_test, benchmarks)\n",
    "pearson_results[\"STS-DEV\"], spearman_results[\"STS-DEV\"] = run_experiment(sts_dev, benchmarks)\n",
    "pearson_results[\"STS-TEST\"], spearman_results[\"STS-TEST\"] = run_experiment(sts_test, benchmarks)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For external imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class similarity_benchmarks:\n",
    "    \"\"\"untested, intended usage: \n",
    "    from SentenceSimilarityWithGloveINfersentGoogle import similarity_benchmarks\"\"\"\n",
    "    benchmarks_sim = benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Let's take a look at our results. We'll mostly work with Pearson correlation, as is standard in the literature, except where Spearman correlation sheds additional light on our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "\n",
    "pearson_results_df = pd.DataFrame(pearson_results)\n",
    "pearson_results_df = pearson_results_df.transpose()\n",
    "pearson_results_df = pearson_results_df.rename(columns={i:b[0] for i, b in enumerate(benchmarks)})\n",
    "\n",
    "spearman_results_df = pd.DataFrame(spearman_results)\n",
    "spearman_results_df = spearman_results_df.transpose()\n",
    "spearman_results_df = spearman_results_df.rename(columns={i:b[0] for i, b in enumerate(benchmarks)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "\n",
    "- Simple word2vec embeddings outperform GloVe embeddings.\n",
    "- With word2vec, it's unclear whether using a stoplist or tf-idf weighting helps. With STS it sometimes does; with SICK it does not. Simply computing an unweighted average of all word2vec embeddings consistently performs pretty well.\n",
    "- With GloVe, using a stoplist looks like a very good idea. Using tf-idf weights does not help, with or without a stoplist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained encoders\n",
    "\n",
    "Pre-trained encoders have a lot to be said for them. However, our results indicate they are not yet able to capitalize fully on their training regime. Throughout our tests, Google's Sentence Encoder looks like a better choice than InferSent. However, the Pearson correlation coefficient shows very little difference with Smooth Inverse Frequency. The differences in Spearman correlation are more outspoken. This may indicate that the Google Sentence Encoder more often gets the relative ordering of the sentences right, but not necessarily the relative differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_results_df[[ \"INF\", \"GSE\"]].plot(kind=\"bar\").legend(loc=\"lower left\")\n",
    "spearman_results_df[[ \"INF\", \"GSE\"]].plot(kind=\"bar\").legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "These are the most important conclusions:\n",
    "\n",
    "- When you're computing sentence similarity, word2vec embeddings are a safer choice than GloVe embeddings.\n",
    "- Although an unweighted average of the word embeddings in the sentence holds its own as a simple baseline, Smooth Inverse Frequency is usually a stronger alternative.\n",
    "- When you can use a pre-trained encoder, pick Google's Sentence Encoder, but remember its performance gain may not be all that spectacular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2a8850dac8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x936 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,13)\n",
    "pearson_results_df.plot(kind=\"bar\").legend(loc=\"lower left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_marble2",
   "language": "python",
   "name": "python3_marble2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
