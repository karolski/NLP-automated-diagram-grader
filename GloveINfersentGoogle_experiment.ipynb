{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Measure sentence similarity in a given dataset using Google's and Facebook's encoders \n",
    "\n",
    "### * warning: takes ages on small computers!\n",
    "\n",
    "It is a heavily modified version of nlp-town's <a href=\"https://github.com/nlptown/nlp-notebooks/blob/master/Simple%20Sentence%20Similarity.ipynb\"> notebook </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the input filenames. Feel free to leave them as they are\n",
    "- `INPUT_FILE_NAME`  is a file with students responses to be graded needs to be a .csv file with columns: IDStudent, IDStud, IDClass, Category, Field, Field_en, Accuracy_score, Code, Fieldname\n",
    "- `MODEL_FILE` is a file with model responses. It needs to have the following columns: 'TextName', 'Field1_en', 'Field2_en','Field3_en', 'Field4_en'. The TextName - first columns - needs to contian the name of the task corresponding to \"Category\" Column in the Input file. \n",
    "\n",
    "To be sure, look at the example datafiles provided and replace the content of the columns with the data from your experiment. Remember, that the responses of the students should not be empty. All texts should be in english.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = 'Example_dataset_marble_v2 - 2_data_no_omission.csv'\n",
    "MODEL_FILE = 'correct_answers.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the output filenames (if you change them, you will need to change them in B_ script as well, if you want to run postprocessing.)\n",
    "- `ALL_METHODS_RESULTS_FILE` will contain matched sentences from the model with their similarity scores\n",
    "- `SMOOTH_INVERSE_RESULTS_FILE` - part of the above file containing only SIF method matching and scores\n",
    "- `AVG_WORD2VEC_RESULTS_FILE` - same as above, only using the most primitive avarage of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_METHODS_RESULTS_FILE = \"GSE_INF_complete_result_matched.csv\"\n",
    "GSE_RESULTS_FILE = \"GSE_wv2_matched.csv\"\n",
    "infersent_RESULTS_FILE = \"INF_matched.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries\n",
    "Libraries ```seaborn```, ```tensorflow``` and ```tensorflow_hub``` are not included in the basic setup of the environment (requirements.txt) because of their size. At first you may need to install them. If you encounter \"module not found\" error, execute the lines below in terminal \n",
    "\n",
    "(activate the virtual environment first with `source env/bin/activate`)\n",
    "``\n",
    "pip intall seaborn\n",
    "pip install tensorflow\n",
    "pip install tensorflow_hub\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "class Sentence:\n",
    "    \n",
    "    def __init__(self, sentence):\n",
    "        self.raw = sentence\n",
    "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n",
    "        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InferSent\n",
    "\n",
    "[InferSent](https://github.com/facebookresearch/InferSent) is a pre-trained encoder that produces sentence embeddings. \n",
    "More particularly, it is a BiLSTM with max pooling that was trained on the SNLI dataset, 570k English sentence pairs labelled with one of three categories: entailment, contradiction or neutral. InferSent was developed and trained by Facebook Research.\n",
    "\n",
    "Let's first download the resources we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# !wget -nc https://raw.githubusercontent.com/facebookresearch/InferSent/master/models.py\n",
    "# !wget -nc https://s3.amazonaws.com/senteval/infersent/infersent.allnli.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first time you need to download the infersent1.pkl model. Uncomment and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir encoder\n",
    "# !curl -Lo encoder/infersent1.pkl https://s3.amazonaws.com/senteval/infersent/infersent1.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infersent uses glove model. You can download it by uncommenting and running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -Lo models/ https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "# !cd models && unzip glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_GLOVE = os.path.expanduser(\"models/glove.840B.300d.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from models import InferSent\n",
    "V = 1\n",
    "MODEL_PATH = 'models/infersent1.pkl'\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))\n",
    "infersent.set_w2v_path(PATH_TO_GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # infersent = torch.load('infersent.allnli.pickle')\n",
    "\n",
    "# infersent = torch.load('infersent.allnli.pickle', map_location=lambda storage, loc: storage)\n",
    "# infersent.use_cuda = False\n",
    "# infersent.set_glove_path(PATH_TO_GLOVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the benchmark by having InferSent encode the two sets of sentences and compute the cosine similarity between the corresponding sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def run_inf_benchmark(sentences1, sentences2):\n",
    "    \n",
    "    raw_sentences1 = [sent1.raw for sent1 in sentences1]\n",
    "    raw_sentences2 = [sent2.raw for sent2 in sentences2]\n",
    "    \n",
    "    infersent.build_vocab(raw_sentences1 + raw_sentences2, tokenize=True)\n",
    "    embeddings1 = infersent.encode(raw_sentences1, tokenize=True)\n",
    "    embeddings2 = infersent.encode(raw_sentences2, tokenize=True)\n",
    "    \n",
    "    inf_sims = []\n",
    "    for (emb1, emb2) in zip(embeddings1, embeddings2): \n",
    "        sim = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "        inf_sims.append(sim)\n",
    "\n",
    "    return inf_sims   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Sentence Encoder\n",
    "\n",
    "The [Google Sentence Encoder](https://www.tensorflow.org/hub/modules/google/universal-sentence-encoder/1) is Google's answer to Facebook's InferSent. It comes in two forms: \n",
    "\n",
    "- a Transformer model that takes the element-wise sum of the context-aware word representations produced by the encoding subgraph of a Transformer model.\n",
    "- a Deep Averaging Network (DAN) where input embeddings for words and bigrams are averaged together and passed through a feed-forward deep neural network.\n",
    "\n",
    "The Transformer model tends to give better results, but at the time of writing, only the DAN-based encoder was available.\n",
    "\n",
    "In contrast to InferSent, the Google Sentence Encoder was trained on a combination of unsupervised data (in a skip-thought-like task) and supervised data (the SNLI corpus).\n",
    "\n",
    "The Google Sentence Encoder can be loaded from the Tensorflow Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "#in case ssl errors appear this part may need to be commented out\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "embed = hub.Module(\"http://tfhub.dev/google/universal-sentence-encoder/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like InferSent above, we'll have the it encode the two sets of sentences and return the similarities between the embeddings it produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gse_benchmark(sentences1, sentences2):\n",
    "    sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "    sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "    sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\n",
    "    sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\n",
    "        \n",
    "    sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "      \n",
    "        [gse_sims] = session.run(\n",
    "            [sim_scores],\n",
    "            feed_dict={\n",
    "                sts_input1: [sent1.raw for sent1 in sentences1],\n",
    "                sts_input2: [sent2.raw for sent2 in sentences2]\n",
    "            })\n",
    "    return gse_sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Finally, it's time to run the actual experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "\n",
    "benchmarks = [\n",
    "              (\"GSE\", run_gse_benchmark),\n",
    "#               (\"INF\", run_inf_benchmark)\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to our dataset\n",
    "First we open our input file, for example:\n",
    "\n",
    "`INPUT_FILE_NAME = 'Example_dataset_marble_v2 - 2_data_no_omission.csv'` \n",
    "- you can set the input file name at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\outl0\\strokewidth0 \\strokec2 IDStudent</th>\n",
       "      <th>IDStud</th>\n",
       "      <th>IDClass</th>\n",
       "      <th>Category</th>\n",
       "      <th>Field</th>\n",
       "      <th>Field_en</th>\n",
       "      <th>Accuracy_score</th>\n",
       "      <th>Code</th>\n",
       "      <th>Fieldname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8I1F</td>\n",
       "      <td>8I1FH3B</td>\n",
       "      <td>H3B</td>\n",
       "      <td>Beton</td>\n",
       "      <td>liften gaan vast zitten</td>\n",
       "      <td>elevators get stuck</td>\n",
       "      <td>4</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11I6F</td>\n",
       "      <td>11I6FH3E</td>\n",
       "      <td>H3E</td>\n",
       "      <td>Beton</td>\n",
       "      <td>Beton krimpt als het warm word</td>\n",
       "      <td>Concrete shrinks as the hot word</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12I5F</td>\n",
       "      <td>12I5FA3</td>\n",
       "      <td>A3</td>\n",
       "      <td>Beton</td>\n",
       "      <td>Door de centrale verwarming krimpt het beton</td>\n",
       "      <td>By heating the concrete shrinks</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13I6F</td>\n",
       "      <td>13I6FA3</td>\n",
       "      <td>A3</td>\n",
       "      <td>Beton</td>\n",
       "      <td>betonnen gebouwen krimpen bij centrale verwarming</td>\n",
       "      <td>concrete buildings shrink by central heating</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20I2F</td>\n",
       "      <td>20I2F3VA</td>\n",
       "      <td>3VA</td>\n",
       "      <td>Beton</td>\n",
       "      <td>beton wordt na een tijdje kleiner</td>\n",
       "      <td>concrete decreases after a while</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  \\outl0\\strokewidth0 \\strokec2 IDStudent    IDStud IDClass Category  \\\n",
       "0                                    8I1F   8I1FH3B     H3B    Beton   \n",
       "1                                   11I6F  11I6FH3E     H3E    Beton   \n",
       "2                                   12I5F   12I5FA3      A3    Beton   \n",
       "3                                   13I6F   13I6FA3      A3    Beton   \n",
       "4                                   20I2F  20I2F3VA     3VA    Beton   \n",
       "\n",
       "                                               Field  \\\n",
       "0                            liften gaan vast zitten   \n",
       "1                     Beton krimpt als het warm word   \n",
       "2       Door de centrale verwarming krimpt het beton   \n",
       "3  betonnen gebouwen krimpen bij centrale verwarming   \n",
       "4                  beton wordt na een tijdje kleiner   \n",
       "\n",
       "                                       Field_en Accuracy_score Code  Fieldname  \n",
       "0                           elevators get stuck              4    g          1  \n",
       "1              Concrete shrinks as the hot word              3    g          1  \n",
       "2               By heating the concrete shrinks              3    g          1  \n",
       "3  concrete buildings shrink by central heating              3    g          1  \n",
       "4              concrete decreases after a while              3    g          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(INPUT_FILE_NAME)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the sentences\n",
    "Declaring the main experiment function. The function below will run similarity measures for each responso of the student and check which sentence from the model is the most similar to students response. Thank it will match the most similar one and save the similarity score. This procedure takes place for all the similarity measures in `benchmarks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_match(df, model, benchmarks): \n",
    "    \"\"\"The function will run each of similarity measures in benchmarks \n",
    "    for each respons of the student and check which \n",
    "    sentence from the model is the most similar to student's \n",
    "    response. Than it will match the most similar model sentence \n",
    "    and save the similarity score. \"\"\"\n",
    "    \n",
    "    size = len(model.index)\n",
    "    text_frame = df.copy()\n",
    "    sims = {\"stud_sentence\":[],\n",
    "            \"stud_field\":[],}\n",
    "    for label, method in benchmarks:\n",
    "        sims[label+\"_all_scores\"] = []\n",
    "        sims[label+\"_similarity\"] = []\n",
    "        sims[label+\"_aimed_sentence\"] = []\n",
    "        sims[label+\"_aimed_field\"] = []\n",
    "        \n",
    "    for index, row in text_frame.iterrows():\n",
    "        stud_sentence = row[\"Field_en\"]\n",
    "        sims[\"stud_sentence\"].append(stud_sentence)\n",
    "        sims[\"stud_field\"].append(row[\"Fieldname\"])\n",
    "        student_sentences = [Sentence(stud_sentence)]*size\n",
    "        model_sentences = model[row['Category']].apply(lambda s: Sentence(s))\n",
    "    #   pearson_cors, spearman_cors = [], []\n",
    "        for label, method in benchmarks:\n",
    "            similarity_scores = method(student_sentences, model_sentences)\n",
    "            similarity = max(similarity_scores)\n",
    "            index = np.argmax(similarity_scores)\n",
    "            aimed_sentence = model_sentences.iloc[index]\n",
    "            aimed_field = model_sentences.index[index]\n",
    "            sims[label+\"_all_scores\"].append(similarity_scores)\n",
    "            sims[label+\"_similarity\"].append(similarity)\n",
    "            sims[label+\"_aimed_sentence\"].append(aimed_sentence.raw)\n",
    "            sims[label+\"_aimed_field\"].append(aimed_field)\n",
    "    frame = pd.DataFrame(sims)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the model file and transposing it, so that text names become columns, and field_numbers become index rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>TextName</th>\n",
       "      <th>Beton</th>\n",
       "      <th>Botox</th>\n",
       "      <th>Geld</th>\n",
       "      <th>Metro</th>\n",
       "      <th>Muziek</th>\n",
       "      <th>Suez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Field1_en</th>\n",
       "      <td>Central heating</td>\n",
       "      <td>Can help prevent muscle tightness</td>\n",
       "      <td>People should not be distracted for too long risk</td>\n",
       "      <td>Waste need not be processed in some way</td>\n",
       "      <td>learn to read and play music</td>\n",
       "      <td>No natural connection Western Indian Ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field2_en</th>\n",
       "      <td>Concrete dries out</td>\n",
       "      <td>Can help against wrinkles between the eyes and...</td>\n",
       "      <td>A person may experience only short deep happin...</td>\n",
       "      <td>Artificial reef constructed</td>\n",
       "      <td>Improving mathematics vaardigheiten</td>\n",
       "      <td>Ships make long trip around African continent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field3_en</th>\n",
       "      <td>Buildings are smaller</td>\n",
       "      <td>People look younger</td>\n",
       "      <td>People get used to luxury</td>\n",
       "      <td>More plankton and marine fauna</td>\n",
       "      <td>Can help bring back old memories</td>\n",
       "      <td>Shorter waterway needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field4_en</th>\n",
       "      <td>Elevators Bliven hang</td>\n",
       "      <td>Facial expression can change</td>\n",
       "      <td>Money does not gellukig long time</td>\n",
       "      <td>More fish (such as mackerel, grouper, sea fish...</td>\n",
       "      <td>Higher scores on IQ tests</td>\n",
       "      <td>Suez canal dug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "TextName                   Beton  \\\n",
       "Field1_en        Central heating   \n",
       "Field2_en     Concrete dries out   \n",
       "Field3_en  Buildings are smaller   \n",
       "Field4_en  Elevators Bliven hang   \n",
       "\n",
       "TextName                                               Botox  \\\n",
       "Field1_en                  Can help prevent muscle tightness   \n",
       "Field2_en  Can help against wrinkles between the eyes and...   \n",
       "Field3_en                                People look younger   \n",
       "Field4_en                       Facial expression can change   \n",
       "\n",
       "TextName                                                Geld  \\\n",
       "Field1_en  People should not be distracted for too long risk   \n",
       "Field2_en  A person may experience only short deep happin...   \n",
       "Field3_en                          People get used to luxury   \n",
       "Field4_en                  Money does not gellukig long time   \n",
       "\n",
       "TextName                                               Metro  \\\n",
       "Field1_en            Waste need not be processed in some way   \n",
       "Field2_en                        Artificial reef constructed   \n",
       "Field3_en                     More plankton and marine fauna   \n",
       "Field4_en  More fish (such as mackerel, grouper, sea fish...   \n",
       "\n",
       "TextName                                Muziek  \\\n",
       "Field1_en         learn to read and play music   \n",
       "Field2_en  Improving mathematics vaardigheiten   \n",
       "Field3_en     Can help bring back old memories   \n",
       "Field4_en            Higher scores on IQ tests   \n",
       "\n",
       "TextName                                            Suez  \n",
       "Field1_en     No natural connection Western Indian Ocean  \n",
       "Field2_en  Ships make long trip around African continent  \n",
       "Field3_en                        Shorter waterway needed  \n",
       "Field4_en                                 Suez canal dug  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_frame = pd.read_csv(MODEL_FILE, index_col=0)\n",
    "exp_frame2 = data.copy()\n",
    "model_frame = model_frame[[ 'Field1_en', 'Field2_en','Field3_en', 'Field4_en']]\n",
    "model_frame = model_frame.transpose()\n",
    "model_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment on the copy of the original\n",
    "frame_sim2 = run_all_match(exp_frame2, model_frame, benchmarks)\n",
    "frame_sim2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append exta columns to the experiments result: 'IDStud', 'IDClass', \"Category\",\"Accuracy_score\", \"Code\",\"Fieldname\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_sim2 = pd.concat([frame_sim2, \n",
    "                        exp_frame2[['IDStud', 'IDClass', \n",
    "                                    \"Category\",\"Accuracy_score\",\n",
    "                                    \"Code\",\"Fieldname\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the all the columns to `ALL_METHODS_RESULTS_FILE` and specific methods columns to other -`RESULTS_FILE`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_sim2.to_csv(ALL_METHODS_RESULTS_FILE)\n",
    "sif_matched = frame_sim2[[\"INF_aimed_sentence\", \n",
    "            \"INF_aimed_field\", \n",
    "            'INF_similarity',\n",
    "            'stud_field',\n",
    "            'stud_sentence',\n",
    "            'IDStud', 'IDClass', \n",
    "            \"Category\",\"Accuracy_score\",\n",
    "            \"Code\",\"Fieldname\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sif_matched.to_csv(SMOOTH_INVERSE_RESULTS_FILE)\n",
    "avg_w2v_matched = frame_sim2[[\"GSE_aimed_sentence\", \n",
    "            \"GSE_aimed_field\", \n",
    "            'GSE_similarity',\n",
    "            'stud_field',\n",
    "            'stud_sentence',\n",
    "            'IDStud', 'IDClass', \n",
    "            \"Category\",\"Accuracy_score\",\n",
    "            \"Code\",\"Fieldname\"]].copy()\n",
    "avg_w2v_matched.to_csv(\"avg_wv2_matched.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
